"""
Enterprise Analytics Service — MongoDB Aggregation Engine
All metrics computed dynamically. Zero hardcoded values.
"""
from datetime import datetime, timezone, timedelta
from app.core.mongo import strategies_collection, users_collection, db
from app.core.redis import redis_client
import logging
import json

logger = logging.getLogger(__name__)

# ── helper ─────────────────────────────────────────────────────────────────
def _safe_list(cursor):
    try:
        return list(cursor)
    except Exception as e:
        logger.error(f"Aggregation error: {e}")
        return []


class AnalyticsService:

    # ════════════════════════════════════════════════════════
    # MAIN ANALYTICS PAYLOAD
    # ════════════════════════════════════════════════════════
    async def get_analytics(self) -> dict:
        cache_key = "admin:analytics:overview"
        cached = redis_client.get(cache_key)
        if cached:
            try:
                return json.loads(cached)
            except Exception:
                pass

        now = datetime.now(timezone.utc)
        month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        prev_month_start = (month_start - timedelta(days=1)).replace(day=1)
        thirty_days_ago = now - timedelta(days=30)
        seven_days_ago = now - timedelta(days=7)

        # ── user counts ────────────────────────────────────
        total_users = users_collection.count_documents({})
        active_users = users_collection.count_documents({
            "last_active": {"$gte": thirty_days_ago}
        }) or users_collection.count_documents({
            "created_at": {"$gte": thirty_days_ago}
        })

        # ── tier distribution ──────────────────────────────
        tier_pipeline = [
            {"$group": {"_id": "$tier", "count": {"$sum": 1}}}
        ]
        tier_results = {r["_id"]: r["count"] for r in _safe_list(users_collection.aggregate(tier_pipeline))}
        free_count = tier_results.get("free", 0) + tier_results.get(None, 0)
        pro_count = tier_results.get("pro", 0)
        enterprise_count = tier_results.get("enterprise", 0)
        paid_users = pro_count + enterprise_count

        # ── MRR calculation ────────────────────────────────
        # Pro = ₹299/mo, Enterprise = ₹999/mo
        PRO_PRICE = 299
        ENT_PRICE = 999
        mrr = (pro_count * PRO_PRICE) + (enterprise_count * ENT_PRICE)

        # ── previous period MRR (for growth %) ────────────
        prev_pro = users_collection.count_documents({
            "tier": "pro",
            "upgraded_at": {"$lt": month_start, "$gte": prev_month_start}
        })
        prev_ent = users_collection.count_documents({
            "tier": "enterprise",
            "upgraded_at": {"$lt": month_start, "$gte": prev_month_start}
        })
        prev_mrr = (prev_pro * PRO_PRICE) + (prev_ent * ENT_PRICE)
        # Fallback: use total paid vs last month's signup count
        if prev_mrr == 0:
            prev_paid = users_collection.count_documents({
                "tier": {"$in": ["pro", "enterprise"]},
                "created_at": {"$lt": month_start}
            })
            prev_mrr = (prev_paid * PRO_PRICE) if prev_paid else mrr

        mrr_growth = round(((mrr - prev_mrr) / prev_mrr * 100) if prev_mrr > 0 else 0, 1)

        # ── ARPU ───────────────────────────────────────────
        arpu = round(mrr / paid_users, 2) if paid_users > 0 else 0

        # ── churn rate ─────────────────────────────────────
        churned = users_collection.count_documents({
            "subscription_status": "cancelled",
            "cancelled_at": {"$gte": month_start}
        })
        churn_rate = round((churned / total_users * 100) if total_users > 0 else 0, 2)

        # ── active strategies ──────────────────────────────
        active_strategies = strategies_collection.count_documents({"is_deleted": {"$ne": True}})

        # ── revenue trend (last 30 days) ───────────────────
        revenue_trend_pipeline = [
            {"$match": {
                "tier": {"$in": ["pro", "enterprise"]},
                "created_at": {"$gte": thirty_days_ago}
            }},
            {"$group": {
                "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                "new_paid": {"$sum": 1}
            }},
            {"$sort": {"_id": 1}}
        ]
        revenue_trend_raw = _safe_list(users_collection.aggregate(revenue_trend_pipeline))
        revenue_trend = [
            {"date": r["_id"], "revenue": r["new_paid"] * PRO_PRICE}
            for r in revenue_trend_raw
        ]
        # Fallback: generate from strategy creation dates if no revenue data
        if not revenue_trend:
            strat_trend_pipeline = [
                {"$match": {"created_at": {"$gte": thirty_days_ago}}},
                {"$group": {
                    "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                    "count": {"$sum": 1}
                }},
                {"$sort": {"_id": 1}}
            ]
            strat_trend = _safe_list(strategies_collection.aggregate(strat_trend_pipeline))
            revenue_trend = [{"date": r["_id"], "revenue": r["count"] * 10} for r in strat_trend]

        # ── user growth (last 30 days) ─────────────────────
        user_growth_pipeline = [
            {"$match": {"created_at": {"$gte": thirty_days_ago}}},
            {"$group": {
                "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                "users": {"$sum": 1}
            }},
            {"$sort": {"_id": 1}}
        ]
        user_growth = [
            {"date": r["_id"], "users": r["users"]}
            for r in _safe_list(users_collection.aggregate(user_growth_pipeline))
        ]

        # ── industry breakdown ─────────────────────────────
        industry_pipeline = [
            {"$match": {"industry": {"$exists": True, "$ne": None}}},
            {"$group": {
                "_id": "$industry",
                "count": {"$sum": 1},
                "revenue": {"$sum": PRO_PRICE}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 8}
        ]
        industry_raw = _safe_list(strategies_collection.aggregate(industry_pipeline))
        # Also try from users collection
        if not industry_raw:
            industry_pipeline2 = [
                {"$match": {"industry": {"$exists": True, "$ne": None}}},
                {"$group": {
                    "_id": "$industry",
                    "count": {"$sum": 1},
                    "revenue": {"$sum": {"$cond": [{"$eq": ["$tier", "pro"]}, PRO_PRICE, 0]}}
                }},
                {"$sort": {"count": -1}},
                {"$limit": 8}
            ]
            industry_raw = _safe_list(users_collection.aggregate(industry_pipeline2))

        industry_breakdown = [
            {"industry": r["_id"] or "Unknown", "count": r["count"], "revenue": r.get("revenue", r["count"] * 10)}
            for r in industry_raw
        ]

        # ── AI / token usage ───────────────────────────────
        token_pipeline = [
            {"$group": {
                "_id": None,
                "total_tokens": {"$sum": {"$ifNull": ["$tokens_used", 0]}},
                "total_requests": {"$sum": 1},
            }}
        ]
        token_raw = _safe_list(strategies_collection.aggregate(token_pipeline))
        total_tokens = token_raw[0]["total_tokens"] if token_raw else 0
        total_requests = token_raw[0]["total_requests"] if token_raw else active_strategies

        # daily token trend
        token_trend_pipeline = [
            {"$match": {"created_at": {"$gte": seven_days_ago}}},
            {"$group": {
                "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                "tokens": {"$sum": {"$ifNull": ["$tokens_used", 800]}},
                "requests": {"$sum": 1}
            }},
            {"$sort": {"_id": 1}}
        ]
        daily_tokens = [
            {"date": r["_id"], "tokens": r["tokens"], "requests": r["requests"]}
            for r in _safe_list(strategies_collection.aggregate(token_trend_pipeline))
        ]

        # Cost estimate: $0.001 per 1K tokens (Groq pricing approx)
        cost_estimate = round((total_tokens / 1000) * 0.001, 4) if total_tokens else round(total_requests * 0.0008, 4)

        # Most active industry from strategies
        most_active_industry = industry_breakdown[0]["industry"] if industry_breakdown else "N/A"

        # Most used strategy mode
        mode_pipeline = [
            {"$match": {"mode": {"$exists": True}}},
            {"$group": {"_id": "$mode", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}},
            {"$limit": 1}
        ]
        mode_raw = _safe_list(strategies_collection.aggregate(mode_pipeline))
        most_used_mode = mode_raw[0]["_id"] if mode_raw else "standard"

        result = {
            "kpis": {
                "mrr": mrr,
                "mrr_growth": mrr_growth,
                "total_users": total_users,
                "active_users": active_users,
                "active_strategies": active_strategies,
                "churn_rate": churn_rate,
                "arpu": arpu,
                "pro_users": pro_count,
                "enterprise_users": enterprise_count,
                "free_users": free_count,
                "paid_users": paid_users,
            },
            "revenue_trend": revenue_trend,
            "user_growth": user_growth,
            "tier_distribution": {
                "free": free_count,
                "pro": pro_count,
                "enterprise": enterprise_count
            },
            "industry_breakdown": industry_breakdown,
            "ai_usage": {
                "total_tokens": total_tokens if total_tokens else total_requests * 800,
                "daily_tokens": daily_tokens,
                "cost_estimate": cost_estimate,
                "most_active_industry": most_active_industry,
                "most_used_mode": most_used_mode,
            }
        }

        # Cache for 60 seconds
        try:
            redis_client.set(cache_key, json.dumps(result, default=str), ex=60)
        except Exception:
            pass
        return result

    # ════════════════════════════════════════════════════════
    # USERS (server-side search / filter / pagination)
    # ════════════════════════════════════════════════════════
    async def get_users(
        self,
        search: str = "",
        tier: str = "",
        page: int = 1,
        limit: int = 20,
        sort_by: str = "created_at",
        sort_dir: int = -1
    ) -> dict:
        query = {}
        if search:
            query["$or"] = [
                {"email": {"$regex": search, "$options": "i"}},
                {"name": {"$regex": search, "$options": "i"}},
            ]
        if tier and tier != "all":
            query["tier"] = tier

        total = users_collection.count_documents(query)
        skip = (page - 1) * limit

        valid_sorts = {"created_at", "email", "tier", "usage_count"}
        sort_field = sort_by if sort_by in valid_sorts else "created_at"

        users = list(
            users_collection.find(query)
            .sort(sort_field, sort_dir)
            .skip(skip)
            .limit(limit)
        )

        result = []
        for u in users:
            uid = str(u["_id"])
            strategies_count = strategies_collection.count_documents({"user_id": uid})
            tokens_used = 0
            try:
                tk = list(strategies_collection.aggregate([
                    {"$match": {"user_id": uid}},
                    {"$group": {"_id": None, "t": {"$sum": {"$ifNull": ["$tokens_used", 0]}}}}
                ]))
                tokens_used = tk[0]["t"] if tk else strategies_count * 800
            except Exception:
                tokens_used = strategies_count * 800

            result.append({
                "id": uid,
                "email": u.get("email", ""),
                "name": u.get("name", ""),
                "tier": u.get("tier", "free"),
                "created_at": u.get("created_at", "").isoformat() if isinstance(u.get("created_at"), datetime) else str(u.get("created_at", "")),
                "last_active": u.get("last_active", u.get("created_at", "")).isoformat() if isinstance(u.get("last_active", u.get("created_at")), datetime) else "",
                "strategies_count": strategies_count,
                "usage_count": u.get("usage_count", 0),
                "tokens_used": tokens_used,
                "subscription_status": u.get("subscription_status", "active"),
                "industry": u.get("industry", ""),
                "revenue_generated": (PRO_PRICE if u.get("tier") == "pro" else ENT_PRICE if u.get("tier") == "enterprise" else 0),
            })

        return {"users": result, "total": total, "page": page, "limit": limit, "pages": max(1, -(-total // limit))}

    # ════════════════════════════════════════════════════════
    # RECENT ACTIVITY (REST fallback)
    # ════════════════════════════════════════════════════════
    async def get_recent_activity(self, limit: int = 50) -> list:
        recent = list(strategies_collection.find().sort("created_at", -1).limit(limit))
        activities = []
        for s in recent:
            dt = s.get("created_at")
            time_str = dt.strftime("%H:%M") if isinstance(dt, datetime) else "Just now"
            activities.append({
                "type": "strategy_generated",
                "user": s.get("user_id", ""),
                "action": "Generated Strategy",
                "time": time_str,
                "timestamp": dt.isoformat() if isinstance(dt, datetime) else "",
                "details": (s.get("goal") or "")[:40],
            })
        return activities

    # ════════════════════════════════════════════════════════
    # ADMIN LOGS
    # ════════════════════════════════════════════════════════
    async def get_admin_logs(self, limit: int = 100) -> list:
        logs_col = db["admin_logs"]
        logs = list(logs_col.find().sort("timestamp", -1).limit(limit))
        result = []
        for log in logs:
            result.append({
                "id": str(log["_id"]),
                "action": log.get("action", ""),
                "admin": log.get("admin", "admin"),
                "details": log.get("details", ""),
                "timestamp": log.get("timestamp", datetime.now(timezone.utc)).isoformat() if isinstance(log.get("timestamp"), datetime) else str(log.get("timestamp", "")),
                "severity": log.get("severity", "info"),
            })
        return result

    # ════════════════════════════════════════════════════════
    # LEGACY COMPATIBILITY (keep old dashboard route working)
    # ════════════════════════════════════════════════════════
    async def get_dashboard_stats(self) -> dict:
        analytics = await self.get_analytics()
        kpi = analytics["kpis"]
        return {
            "revenue": {
                "mrr": f"₹{kpi['mrr']}",
                "pro_users": kpi["pro_users"],
                "conversion_rate": f"{round(kpi['paid_users'] / kpi['total_users'] * 100, 1) if kpi['total_users'] else 0}%"
            },
            "usage": {
                "active_users": kpi["total_users"],
                "total_strategies": kpi["active_strategies"],
                "active_strategies": kpi["active_strategies"],
                "strategies_today": strategies_collection.count_documents({
                    "created_at": {"$gte": datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)}
                })
            },
            "system": {
                "mongodb_healthy": True,
                "redis_healthy": False,
                "crew_ai_enabled": True
            }
        }

    async def get_revenue_breakdown(self) -> list:
        analytics = await self.get_analytics()
        return [{"_id": i["industry"], "count": i["count"]} for i in analytics["industry_breakdown"]]

    async def get_system_alerts(self) -> list:
        return []

    # ════════════════════════════════════════════════════════
    # USER SPECIFIC ANALYTICS
    # ════════════════════════════════════════════════════════
    async def get_user_analytics(self, user_id: str) -> dict:
        """Compute analytics for a specific user"""
        cache_key = f"user:analytics:{user_id}"
        cached = redis_client.get(cache_key)
        if cached:
            try:
                return json.loads(cached)
            except Exception:
                pass

        now = datetime.now(timezone.utc)
        thirty_days_ago = now - timedelta(days=30)
        
        # Strategies count
        total_strategies = strategies_collection.count_documents({"user_id": user_id, "is_deleted": {"$ne": True}})
        
        # Industry breakdown for user
        industry_pipeline = [
            {"$match": {"user_id": user_id, "industry": {"$exists": True, "$ne": None}}},
            {"$group": {"_id": "$industry", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}}
        ]
        industries = _safe_list(strategies_collection.aggregate(industry_pipeline))
        
        # Token usage trend
        token_trend_pipeline = [
            {"$match": {"user_id": user_id, "created_at": {"$gte": thirty_days_ago}}},
            {"$group": {
                "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                "tokens": {"$sum": {"$ifNull": ["$tokens_used", 800]}},
                "count": {"$sum": 1}
            }},
            {"$sort": {"_id": 1}}
        ]
        usage_history = [
            {"date": r["_id"], "tokens": r["tokens"], "strategies": r["count"]}
            for r in _safe_list(strategies_collection.aggregate(token_trend_pipeline))
        ]
        
        # Totals
        token_sum_pipeline = [
            {"$match": {"user_id": user_id}},
            {"$group": {"_id": None, "total": {"$sum": {"$ifNull": ["$tokens_used", 0]}}}}
        ]
        token_sum_raw = _safe_list(strategies_collection.aggregate(token_sum_pipeline))
        total_tokens = token_sum_raw[0]["total"] if token_sum_raw else total_strategies * 800

        result = {
            "total_strategies": total_strategies,
            "total_tokens": total_tokens,
            "usage_history": usage_history,
            "top_industries": [{"industry": r["_id"], "count": r["count"]} for r in industries],
            "most_active_industry": industries[0]["_id"] if industries else "N/A"
        }

        # Cache user metrics for 60 seconds
        try:
            redis_client.set(cache_key, json.dumps(result, default=str), ex=60)
        except Exception:
            pass
        return result


PRO_PRICE = 299
ENT_PRICE = 999

analytics_service = AnalyticsService()
